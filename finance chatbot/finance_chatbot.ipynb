{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8957483,"sourceType":"datasetVersion","datasetId":5391052}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Finance ChatBot","metadata":{}},{"cell_type":"markdown","source":"The `TinyLlama-1.1B-Chat-v1.0` model is fine-tuned on the [finance_alpaca.json](https://github.com/JoyM268/Intel-Unnati-Industrial-Training-Program-2024/blob/main/finance%20chatbot/finance_alpaca.json) dataset and later the fine-tuned model  is prompted Questions. The chatbot is fine-tuned to answer finance related questions.","metadata":{}},{"cell_type":"markdown","source":"## Prepare Environment","metadata":{}},{"cell_type":"markdown","source":"Install `intel_extension_for_transformers` Library.","metadata":{}},{"cell_type":"code","source":"!pip install intel-extension-for-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-15T09:15:58.500023Z","iopub.execute_input":"2024-07-15T09:15:58.500747Z","iopub.status.idle":"2024-07-15T09:16:17.255513Z","shell.execute_reply.started":"2024-07-15T09:15:58.500712Z","shell.execute_reply":"2024-07-15T09:16:17.254431Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting intel-extension-for-transformers\n  Downloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (1.26.4)\nCollecting schema (from intel-extension-for-transformers)\n  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (6.0.1)\nCollecting neural-compressor (from intel-extension-for-transformers)\n  Downloading neural_compressor-2.6-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (4.42.3)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (1.2.14)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (4.10.0.84)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (2.2.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (9.5.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (3.9.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (9.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (2.32.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (1.2.2)\nCollecting pycocotools (from neural-compressor->intel-extension-for-transformers)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->intel-extension-for-transformers) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (0.23.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (4.66.4)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.13->neural-compressor->intel-extension-for-transformers) (1.14.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->intel-extension-for-transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->intel-extension-for-transformers) (4.9.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2023.4)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->neural-compressor->intel-extension-for-transformers) (0.2.13)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->neural-compressor->intel-extension-for-transformers) (3.7.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (2024.7.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (1.4.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->neural-compressor->intel-extension-for-transformers) (1.16.0)\nDownloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl (45.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading neural_compressor-2.6-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: schema, pycocotools, neural-compressor, intel-extension-for-transformers\nSuccessfully installed intel-extension-for-transformers-1.4.2 neural-compressor-2.6 pycocotools-2.0.8 schema-0.7.7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Clone the `intel-extension-for-transformers` git repository.","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/intel/intel-extension-for-transformers.git","metadata":{"execution":{"iopub.status.busy":"2024-07-15T09:16:29.890290Z","iopub.execute_input":"2024-07-15T09:16:29.890932Z","iopub.status.idle":"2024-07-15T09:17:47.829712Z","shell.execute_reply.started":"2024-07-15T09:16:29.890898Z","shell.execute_reply":"2024-07-15T09:17:47.828745Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'intel-extension-for-transformers'...\nremote: Enumerating objects: 1682035, done.\u001b[K\nremote: Counting objects: 100% (116683/116683), done.\u001b[K\nremote: Compressing objects: 100% (13586/13586), done.\u001b[K\nremote: Total 1682035 (delta 63043), reused 113533 (delta 60254), pack-reused 1565352\u001b[K\nReceiving objects: 100% (1682035/1682035), 595.02 MiB | 14.33 MiB/s, done.\nResolving deltas: 100% (898941/898941), done.\nUpdating files: 100% (3217/3217), done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Install the necessary requirements given in [requirements.txt](https://github.com/JoyM268/Intel-Unnati-Industrial-Training-Program-2024/blob/main/requirements/requirements.txt) file.","metadata":{}},{"cell_type":"code","source":"%cd ./intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/\n!pip install -r requirements.txt\n%cd ../../../","metadata":{"execution":{"iopub.status.busy":"2024-07-15T09:17:51.632029Z","iopub.execute_input":"2024-07-15T09:17:51.632891Z","iopub.status.idle":"2024-07-15T09:21:49.948132Z","shell.execute_reply.started":"2024-07-15T09:17:51.632855Z","shell.execute_reply":"2024-07-15T09:21:49.947063Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.32.1)\nCollecting cchardet (from -r requirements.txt (line 2))\n  Downloading cchardet-2.1.7.tar.gz (653 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops (from -r requirements.txt (line 3))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting evaluate (from -r requirements.txt (line 4))\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.108.0)\nCollecting fschat==0.2.35 (from -r requirements.txt (line 6))\n  Downloading fschat-0.2.35-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.23.4)\nCollecting intel_extension_for_pytorch==2.3.0 (from -r requirements.txt (line 8))\n  Downloading intel_extension_for_pytorch-2.3.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting lm-eval (from -r requirements.txt (line 9))\n  Downloading lm_eval-0.4.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: neural-compressor in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.6)\nCollecting neural_speed==1.0a0 (from -r requirements.txt (line 11))\n  Downloading neural_speed-1.0a0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.3 kB)\nCollecting numpy==1.23.5 (from -r requirements.txt (line 12))\n  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nRequirement already satisfied: onnx>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.16.1)\nCollecting optimum (from -r requirements.txt (line 14))\n  Downloading optimum-1.21.2-py3-none-any.whl.metadata (19 kB)\nCollecting optimum-intel (from -r requirements.txt (line 15))\n  Downloading optimum_intel-1.18.1-py3-none-any.whl.metadata (16 kB)\nCollecting peft==0.6.2 (from -r requirements.txt (line 16))\n  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\nCollecting pydantic==1.10.13 (from -r requirements.txt (line 17))\n  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (1.0.0)\nCollecting python-multipart (from -r requirements.txt (line 19))\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting rouge_score (from -r requirements.txt (line 20))\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacremoses (from -r requirements.txt (line 21))\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nCollecting shortuuid (from -r requirements.txt (line 22))\n  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (0.32.0.post1)\nRequirement already satisfied: tensorflow>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (2.15.0)\nCollecting torch==2.3.0 (from -r requirements.txt (line 25))\n  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting torchaudio==2.3.0 (from -r requirements.txt (line 26))\n  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: transformers>=4.35.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (4.42.3)\nCollecting transformers_stream_generator (from -r requirements.txt (line 28))\n  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 29)) (0.25.0)\nCollecting vllm (from -r requirements.txt (line 30))\n  Downloading vllm-0.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.2 kB)\nCollecting yacs (from -r requirements.txt (line 31))\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (3.9.1)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (0.27.0)\nCollecting markdown2[all] (from fschat==0.2.35->-r requirements.txt (line 6))\n  Downloading markdown2-2.5.0-py2.py3-none-any.whl.metadata (2.2 kB)\nCollecting nh3 (from fschat==0.2.35->-r requirements.txt (line 6))\n  Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (3.0.42)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r requirements.txt (line 6)) (13.7.0)\nCollecting tiktoken (from fschat==0.2.35->-r requirements.txt (line 6))\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from intel_extension_for_pytorch==2.3.0->-r requirements.txt (line 8)) (5.9.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from intel_extension_for_pytorch==2.3.0->-r requirements.txt (line 8)) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r requirements.txt (line 16)) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r requirements.txt (line 16)) (4.66.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r requirements.txt (line 16)) (0.4.3)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.13->-r requirements.txt (line 17)) (4.9.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r requirements.txt (line 25)) (2024.5.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.0 (from torch==2.3.0->-r requirements.txt (line 25))\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r requirements.txt (line 25))\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 4)) (2.20.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 4)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 4)) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 4)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 4)) (0.70.16)\nCollecting jsonlines (from lm-eval->-r requirements.txt (line 9))\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r requirements.txt (line 9)) (2.10.1)\nRequirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r requirements.txt (line 9)) (2.13.1)\nCollecting pytablewriter (from lm-eval->-r requirements.txt (line 9))\n  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\nCollecting sacrebleu>=1.5.0 (from lm-eval->-r requirements.txt (line 9))\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r requirements.txt (line 9)) (1.2.2)\nCollecting sqlitedict (from lm-eval->-r requirements.txt (line 9))\n  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tqdm-multiprocess (from lm-eval->-r requirements.txt (line 9))\n  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r requirements.txt (line 9)) (0.22.0)\nCollecting word2number (from lm-eval->-r requirements.txt (line 9))\n  Downloading word2number-1.1.zip (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r requirements.txt (line 9)) (10.2.0)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (1.2.14)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (4.10.0.84)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (9.5.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (3.9.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (9.0.0)\nRequirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (0.7.7)\nRequirement already satisfied: pycocotools in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r requirements.txt (line 10)) (2.0.8)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx>=1.15.0->-r requirements.txt (line 13)) (3.20.3)\nCollecting coloredlogs (from optimum->-r requirements.txt (line 14))\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r requirements.txt (line 15)) (0.2.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r requirements.txt (line 15)) (69.0.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r requirements.txt (line 15)) (1.11.4)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 20)) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 20)) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 20)) (1.16.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r requirements.txt (line 21)) (2023.12.25)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r requirements.txt (line 21)) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r requirements.txt (line 21)) (1.4.2)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->-r requirements.txt (line 23)) (4.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.3.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (2.4.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 24)) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow>=2.13.0->-r requirements.txt (line 24))\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.2->-r requirements.txt (line 27)) (0.19.1)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r requirements.txt (line 29)) (0.14.0)\nCollecting cmake>=3.21 (from vllm->-r requirements.txt (line 30))\n  Downloading cmake-3.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from vllm->-r requirements.txt (line 30)) (1.11.1.1)\nCollecting openai (from vllm->-r requirements.txt (line 30))\n  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\nINFO: pip is looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\nCollecting vllm (from -r requirements.txt (line 30))\n  Downloading vllm-0.5.0.post1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.1 kB)\n  Downloading vllm-0.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.3 kB)\n  Downloading vllm-0.4.3-cp310-cp310-manylinux1_x86_64.whl.metadata (7.8 kB)\n  Downloading vllm-0.4.2-cp310-cp310-manylinux1_x86_64.whl.metadata (9.1 kB)\n  Downloading vllm-0.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.9 kB)\n  Downloading vllm-0.4.0.post1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\nRequirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.10/site-packages (from vllm->-r requirements.txt (line 30)) (2.9.0)\n  Downloading vllm-0.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\nINFO: pip is still looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n  Downloading vllm-0.3.3-cp310-cp310-manylinux1_x86_64.whl.metadata (7.8 kB)\n  Downloading vllm-0.3.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\n  Downloading vllm-0.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n  Downloading vllm-0.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n  Downloading vllm-0.2.7-cp310-cp310-manylinux1_x86_64.whl.metadata (6.8 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading vllm-0.2.6-cp310-cp310-manylinux1_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from vllm->-r requirements.txt (line 30)) (16.1.0)\n  Downloading vllm-0.2.5-cp310-cp310-manylinux1_x86_64.whl.metadata (6.5 kB)\nCollecting xformers>=0.0.23 (from vllm->-r requirements.txt (line 30))\n  Downloading xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting aioprometheus[starlette] (from vllm->-r requirements.txt (line 30))\n  Downloading aioprometheus-23.12.0-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r requirements.txt (line 23)) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r requirements.txt (line 23)) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r requirements.txt (line 23)) (1.2.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.42.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 4)) (0.6)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r requirements.txt (line 6)) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->intel_extension_for_pytorch==2.3.0->-r requirements.txt (line 8)) (3.1.1)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (0.2.13)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm->-r requirements.txt (line 30)) (4.20.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm->-r requirements.txt (line 30)) (1.0.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.35->-r requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.35->-r requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.35->-r requirements.txt (line 6)) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (2.17.2)\nCollecting portalocker (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9))\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r requirements.txt (line 9)) (5.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->-r requirements.txt (line 9)) (3.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.0.3)\nINFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\nCollecting xformers>=0.0.23 (from vllm->-r requirements.txt (line 30))\n  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from aioprometheus[starlette]->vllm->-r requirements.txt (line 30)) (3.9.10)\nCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm->-r requirements.txt (line 30))\n  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum->-r requirements.txt (line 14))\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->fschat==0.2.35->-r requirements.txt (line 6)) (1.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->-r requirements.txt (line 25)) (2.1.3)\nCollecting wavedrom (from markdown2[all]->fschat==0.2.35->-r requirements.txt (line 6))\n  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting latex2mathml (from markdown2[all]->fschat==0.2.35->-r requirements.txt (line 6))\n  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 4)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 4)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r requirements.txt (line 4)) (2023.4)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->neural-compressor->-r requirements.txt (line 10)) (3.7.5)\nCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\nCollecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\nCollecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\nCollecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->-r requirements.txt (line 25)) (1.3.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 30)) (0.6.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 30)) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 30)) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 30)) (12.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.35->-r requirements.txt (line 6)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r requirements.txt (line 10)) (1.4.5)\nCollecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval->-r requirements.txt (line 9))\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.9->vllm->-r requirements.txt (line 30)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.9->vllm->-r requirements.txt (line 30)) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.9->vllm->-r requirements.txt (line 30)) (0.16.2)\nCollecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.35->-r requirements.txt (line 6))\n  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r requirements.txt (line 24)) (3.2.2)\nDownloading fschat-0.2.35-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading intel_extension_for_pytorch-2.3.0-cp310-cp310-manylinux2014_x86_64.whl (98.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading neural_speed-1.0a0-cp310-cp310-manylinux_2_28_x86_64.whl (23.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.6.2-py3-none-any.whl (174 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m949.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lm_eval-0.4.3-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.21.2-py3-none-any.whl (424 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum_intel-1.18.1-py3-none-any.whl (224 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\nDownloading vllm-0.2.5-cp310-cp310-manylinux1_x86_64.whl (9.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.2/769.2 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\nDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\nDownloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\nDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\nDownloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\nDownloading typepy-1.3.2-py3-none-any.whl (31 kB)\nDownloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\nDownloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: cchardet, rouge_score, transformers_stream_generator, sqlitedict, word2number, quantile-python, wavedrom\n  Building wheel for cchardet (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=143397 sha256=7fb3491ad806509794d016e4f7317ebc6a6e09a62cda0710454808c20ee554cd\n  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=939d81a78470a5a08c32a4dee6847ddc042a075cc65b8723ebddf9b8f30836ad\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12424 sha256=464bb46d61397fe14cb78bc63f518e5607a1944b856184dcac0de353ece43a5a\n  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=7a5144de5cc124b00f8ad7df7d796c0922bfa1635ab1e94c4f03e9b28def6ac9\n  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=5904e37011343a00087153dc4b9cd12eac3a6b290701fb7eec7ae90f3b68561a\n  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n  Building wheel for quantile-python (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3444 sha256=1cfcda524ed6c258ea7dc06f83492325251e7c774246eea0345106d326e88ad8\n  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\n  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=cac1cfce096529138e84c21d33d971d61aa061dc5fe2cb40ccbbf1587ea6171c\n  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\nSuccessfully built cchardet rouge_score transformers_stream_generator sqlitedict word2number quantile-python wavedrom\nInstalling collected packages: word2number, sqlitedict, quantile-python, nh3, cchardet, yacs, triton, tqdm-multiprocess, tcolorpy, svgwrite, shortuuid, sacremoses, python-multipart, pydantic, portalocker, pathvalidate, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, neural_speed, markdown2, latex2mathml, keras, jsonlines, humanfriendly, einops, chardet, aioprometheus, wavedrom, tiktoken, sacrebleu, rouge_score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mbstrdecoder, intel_extension_for_pytorch, coloredlogs, typepy, nvidia-cusolver-cu12, torch, fschat, xformers, transformers_stream_generator, torchaudio, evaluate, DataProperty, vllm, tabledata, peft, optimum, pytablewriter, optimum-intel, lm-eval\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.1.2\n    Uninstalling torchaudio-2.1.2:\n      Successfully uninstalled torchaudio-2.1.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nucx-py 0.38.0 requires libucx<1.16,>=1.15.0, which is not installed.\nucxx 0.38.0 requires libucx>=1.15.0, which is not installed.\nalbumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nchex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\npylibraft 24.6.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nrmm 24.6.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorstore 0.1.63 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.6.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.13 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed DataProperty-1.0.1 aioprometheus-23.12.0 cchardet-2.1.7 chardet-5.2.0 coloredlogs-15.0.1 einops-0.8.0 evaluate-0.4.2 fschat-0.2.35 humanfriendly-10.0 intel_extension_for_pytorch-2.3.0 jsonlines-4.0.0 keras-2.15.0 latex2mathml-3.77.0 lm-eval-0.4.3 markdown2-2.5.0 mbstrdecoder-1.1.3 neural_speed-1.0a0 nh3-0.2.18 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 optimum-1.21.2 optimum-intel-1.18.1 pathvalidate-3.2.0 peft-0.6.2 portalocker-2.10.1 pydantic-1.10.13 pytablewriter-1.2.0 python-multipart-0.0.9 quantile-python-1.1 rouge_score-0.1.2 sacrebleu-2.4.2 sacremoses-0.1.1 shortuuid-1.0.13 sqlitedict-2.1.0 svgwrite-1.4.3 tabledata-1.3.3 tcolorpy-0.1.6 tiktoken-0.7.0 torch-2.3.0 torchaudio-2.3.0 tqdm-multiprocess-0.0.11 transformers_stream_generator-0.0.5 triton-2.3.0 typepy-1.3.2 vllm-0.2.5 wavedrom-2.0.3.post3 word2number-1.1 xformers-0.0.26.post1 yacs-0.1.8\n/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Login Hugging Face\nLogging in hugging face using User Access Token, The access token must be saved as a secret under the secret name `Intel` before logging in.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Intel\")\nlogin(token=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T09:21:52.626339Z","iopub.execute_input":"2024-07-15T09:21:52.627084Z","iopub.status.idle":"2024-07-15T09:21:53.575340Z","shell.execute_reply.started":"2024-07-15T09:21:52.627048Z","shell.execute_reply":"2024-07-15T09:21:53.574332Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Finetuning The Model\nThe [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) model is fine-tuned on the [finance_alpaca.json](https://github.com/JoyM268/Intel-Unnati-Industrial-Training-Program-2024/blob/main/finance%20chatbot/finance_alpaca.json) dataset. Make sure to upload the dataset before fine-tuning the model. The fine-tuned model is saved in the specified `output_dir`, here the output directory is `./finetuned_model`.","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\nfrom intel_extension_for_transformers.neural_chat.config import (\n    ModelArguments,\n    DataArguments,\n    FinetuningArguments,\n    TextGenerationFinetuningConfig,\n)\nfrom intel_extension_for_transformers.neural_chat.chatbot import finetune_model\nmodel_args = ModelArguments(model_name_or_path=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\ndata_args = DataArguments(train_file=\"/kaggle/input/finance/finance_alpaca.json\", validation_split_percentage=1)\ntraining_args = TrainingArguments(\n    output_dir='./finetuned_model',\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=3,\n    overwrite_output_dir=True,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    save_strategy=\"no\",\n    log_level=\"info\",\n    save_total_limit=2,\n    bf16=True,\n)\nfinetune_args = FinetuningArguments()\nfinetune_cfg = TextGenerationFinetuningConfig(\n            model_args=model_args,\n            data_args=data_args,\n            training_args=training_args,\n            finetune_args=finetune_args,\n        )\nfinetune_model(finetune_cfg)","metadata":{"execution":{"iopub.status.busy":"2024-07-15T09:23:52.875746Z","iopub.execute_input":"2024-07-15T09:23:52.876124Z","iopub.status.idle":"2024-07-15T10:48:07.514573Z","shell.execute_reply.started":"2024-07-15T09:23:52.876096Z","shell.execute_reply":"2024-07-15T10:48:07.513598Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"[INFO|training_args.py:2048] 2024-07-15 09:23:52,880 >> PyTorch: setting up devices\n[INFO|training_args.py:1751] 2024-07-15 09:23:52,908 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n[WARNING|_logger.py:72] 2024-07-15 09:23:52,910 >> Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n[INFO|configuration_utils.py:733] 2024-07-15 09:23:53,253 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n[INFO|configuration_utils.py:800] 2024-07-15 09:23:53,255 >> Model config LlamaConfig {\n  \"_name_or_path\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 5632,\n  \"max_position_embeddings\": 2048,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 22,\n  \"num_key_value_heads\": 4,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 09:23:53,484 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 09:23:53,484 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 09:23:53,485 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 09:23:53,486 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 09:23:53,486 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json\nUsing custom data configuration default-ca78c96c4ac7db03\nLoading Dataset Infos from /opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/json\nOverwrite dataset info from restored data version if exists.\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\nFound cached dataset json (/root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\nUsing custom data configuration default-ca78c96c4ac7db03\nLoading Dataset Infos from /opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/json\nOverwrite dataset info from restored data version if exists.\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\nFound cached dataset json (/root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\nUsing custom data configuration default-ca78c96c4ac7db03\nLoading Dataset Infos from /opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/json\nOverwrite dataset info from restored data version if exists.\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\nFound cached dataset json (/root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a)\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a\n[INFO|modeling_utils.py:3556] 2024-07-15 09:23:55,512 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors\n[INFO|modeling_utils.py:1531] 2024-07-15 09:23:55,523 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n[INFO|configuration_utils.py:1000] 2024-07-15 09:23:55,526 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2\n}\n\n[INFO|modeling_utils.py:4364] 2024-07-15 09:23:56,025 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n\n[INFO|modeling_utils.py:4372] 2024-07-15 09:23:56,026 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n[INFO|configuration_utils.py:955] 2024-07-15 09:23:56,276 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json\n[INFO|configuration_utils.py:1000] 2024-07-15 09:23:56,277 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"max_length\": 2048,\n  \"pad_token_id\": 0\n}\n\nLoading cached processed dataset at /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-806c5b5a140a7d55.arrow\nLoading cached processed dataset at /root/.cache/huggingface/datasets/json/default-ca78c96c4ac7db03/0.0.0/7483f22a71512872c377524b97484f6d20c275799bb9e7cd8fb3198178d8220a/cache-88c011e172095a7a.arrow\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.10229075496156657\n","output_type":"stream"},{"name":"stderr","text":"[INFO|trainer.py:642] 2024-07-15 09:23:57,546 >> Using auto half precision backend\n[INFO|trainer.py:2128] 2024-07-15 09:23:58,046 >> ***** Running training *****\n[INFO|trainer.py:2129] 2024-07-15 09:23:58,047 >>   Num examples = 3,733\n[INFO|trainer.py:2130] 2024-07-15 09:23:58,047 >>   Num Epochs = 3\n[INFO|trainer.py:2131] 2024-07-15 09:23:58,048 >>   Instantaneous batch size per device = 4\n[INFO|trainer.py:2134] 2024-07-15 09:23:58,049 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n[INFO|trainer.py:2135] 2024-07-15 09:23:58,051 >>   Gradient Accumulation steps = 2\n[INFO|trainer.py:2136] 2024-07-15 09:23:58,051 >>   Total optimization steps = 1,401\n[INFO|trainer.py:2137] 2024-07-15 09:23:58,054 >>   Number of trainable parameters = 1,126,400\n[WARNING|_logger.py:72] 2024-07-15 09:23:58,147 >> We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1401' max='1401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1401/1401 1:23:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.851400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.829500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[INFO|trainer.py:2383] 2024-07-15 10:47:59,242 >> \n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n[INFO|trainer.py:3478] 2024-07-15 10:47:59,248 >> Saving model checkpoint to ./finetuned_model\n[INFO|tokenization_utils_base.py:2574] 2024-07-15 10:47:59,292 >> tokenizer config file saved in ./finetuned_model/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2583] 2024-07-15 10:47:59,293 >> Special tokens file saved in ./finetuned_model/special_tokens_map.json\n[INFO|trainer.py:3788] 2024-07-15 10:47:59,299 >> \n***** Running Evaluation *****\n[INFO|trainer.py:3790] 2024-07-15 10:47:59,299 >>   Num examples = 38\n[INFO|trainer.py:3793] 2024-07-15 10:47:59,300 >>   Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_loss               =     1.0709\n  eval_ppl                =      2.918\n  eval_runtime            = 0:00:08.20\n  eval_samples            =         38\n  eval_samples_per_second =      4.629\n  eval_steps_per_second   =      1.218\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference with the finetuned model\nThe output files of the fine-tuned model are stored in the `./finetuned_model` directory, therefore the `peft_model_path` is `./finetuned_model` and the `base_model_path` is `TinyLlama/TinyLlama-1.1B-Chat-v1.0`. Here the question to be prompted is being stored in the `query` variable.","metadata":{}},{"cell_type":"code","source":"from intel_extension_for_transformers.neural_chat.models.model_utils import load_model, predict_stream\nfrom transformers import set_seed\nset_seed(27)\n\nbase_model_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\npeft_model_path = \"./finetuned_model\"\n\nload_model(model_name=base_model_path,\n        tokenizer_name=base_model_path,\n        peft_path=peft_model_path,\n        )\n\ntemplate = \"\"\"\n### System:\n- You are a helpful finance chatbot.\n- You answer questions.\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n- You give answers to finance related questions</s>\n### User:\n{}</s>\n### Assistant:\n\"\"\"\n\nquery = \"what is meant by cost of equity?\"\n\nparams = {\n        \"prompt\": template.format(query),\n        \"model_name\": base_model_path,\n        \"use_cache\": True,\n        \"repetition_penalty\": 1.0,\n        \"temperature\": 0.1,\n        \"top_k\": 10,\n        \"top_p\": 0.75,\n        \"num_beams\": 1,\n        \"max_new_tokens\": 1000\n        }\n\nfor new_text in predict_stream(**params):\n    print(new_text, end=\"\", flush=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:51:04.594691Z","iopub.execute_input":"2024-07-15T10:51:04.595058Z","iopub.status.idle":"2024-07-15T10:52:39.286114Z","shell.execute_reply.started":"2024-07-15T10:51:04.595026Z","shell.execute_reply":"2024-07-15T10:52:39.285363Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Loading model TinyLlama/TinyLlama-1.1B-Chat-v1.0\n","output_type":"stream"},{"name":"stderr","text":"[INFO|configuration_utils.py:733] 2024-07-15 10:51:05,080 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n[INFO|configuration_utils.py:800] 2024-07-15 10:51:05,082 >> Model config LlamaConfig {\n  \"_name_or_path\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 5632,\n  \"max_position_embeddings\": 2048,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 22,\n  \"num_key_value_heads\": 4,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 10:51:05,300 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 10:51:05,301 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 10:51:05,301 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 10:51:05,302 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2161] 2024-07-15 10:51:05,303 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json\n[INFO|configuration_utils.py:733] 2024-07-15 10:51:05,658 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n[INFO|configuration_utils.py:800] 2024-07-15 10:51:05,660 >> Model config LlamaConfig {\n  \"_name_or_path\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 5632,\n  \"max_position_embeddings\": 2048,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 22,\n  \"num_key_value_heads\": 4,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.42.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n[INFO|modeling_utils.py:3556] 2024-07-15 10:51:05,663 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors\n[INFO|modeling_utils.py:1531] 2024-07-15 10:51:05,673 >> Instantiating LlamaForCausalLM model under default dtype torch.float32.\n[INFO|configuration_utils.py:1000] 2024-07-15 10:51:05,676 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2\n}\n\n[INFO|modeling_utils.py:4364] 2024-07-15 10:51:07,511 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n\n[INFO|modeling_utils.py:4372] 2024-07-15 10:51:07,512 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n[INFO|configuration_utils.py:955] 2024-07-15 10:51:07,742 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json\n[INFO|configuration_utils.py:1000] 2024-07-15 10:51:07,743 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"max_length\": 2048,\n  \"pad_token_id\": 0\n}\n\n","output_type":"stream"},{"name":"stdout","text":"Cost of equity is a financial metric used to evaluate the cost of capital for a company. It is calculated by dividing the total return on equity (ROE) by the cost of equity (COE). The COE is a measure of the cost of capital for a company, which is the amount of money required to finance the company's operations.\n\nThe cost of equity is important for investors because it provides a measure of the risk associated with investing in a company. It takes into account the cost of capital, which includes interest rates, taxes, and other expenses associated with investing in the company. By comparing the cost of equity to the ROE, investors can determine whether the company's investment is profitable or not.\n\nThe cost of equity is typically calculated using a discounted cash flow (DCF) model. This model assumes that the company will continue to generate future cash flows at a constant rate, and that the cash flows are discounted to their present value using a discount rate. The discount rate is typically based on the risk-free rate of interest, which is the interest rate that would be charged on a similar investment with the same risk.\n\nThe cost of equity is typically expressed as a percentage, and it is calculated by dividing the ROE by the COE. The higher the cost of equity, the more expensive it is to finance the company's operations. A lower cost of equity indicates that the company's investment is more profitable and may be more attractive to investors.\n\nOverall, the cost of equity is an important financial metric for investors to consider when evaluating the risk and return of a company's investment. It provides a measure of the cost of capital and helps investors make informed decisions about investing in a company.","output_type":"stream"}]}]}